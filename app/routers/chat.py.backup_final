"""
Chat Routes for AI Book Assistant
Implements SSE (Server-Sent Events) for real-time chat
"""

from fastapi import APIRouter, Depends, HTTPException, Query, Request
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from typing import Optional, AsyncGenerator
import json
import asyncio
import logging
from datetime import datetime
import uuid
import requests
import random

from app.models.database import get_db
from app.services.book_service import BookService, SessionService
from app.services.ai_service import AIService

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/chat", tags=["Chat"])

# Store active chat sessions in memory (in production, use Redis)
active_chats = {}
# Track message versions to prevent duplicates
message_versions = {}

@router.post("/send")
async def send_message(
    message: str,
    session_id: str,
    db: Session = Depends(get_db)
):
    """
    Send a message to the AI assistant
    """
    try:
        # Generate unique message ID
        message_id = str(uuid.uuid4())
        
        # Store message in active chats
        if session_id not in active_chats:
            active_chats[session_id] = []
            message_versions[session_id] = {}
        
        # Add user message
        user_msg = {
            "id": message_id,
            "role": "user",
            "content": message,
            "timestamp": datetime.now().isoformat(),
            "version": 1
        }
        active_chats[session_id].append(user_msg)
        message_versions[session_id][message_id] = 1
        
        # Process message with AI (async)
        asyncio.create_task(process_ai_response(session_id, message, db))
        
        return {
            "success": True,
            "message_id": message_id,
            "session_id": session_id
        }
        
    except Exception as e:
        logger.error(f"Chat send error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/stream/{session_id}")
async def chat_stream(
    session_id: str,
    request: Request,
    db: Session = Depends(get_db)
):
    """
    SSE endpoint for streaming chat responses
    """
    async def event_generator() -> AsyncGenerator[str, None]:
        """Generate SSE events"""
        client_id = str(uuid.uuid4())
        logger.info(f"Client {client_id} connected to session {session_id}")
        
        # Send initial connection event
        yield f"data: {json.dumps({'type': 'connected', 'session_id': session_id})}\n\n"
        
        # Track what we've sent to THIS specific client
        client_sent_messages = {}
        
        try:
            while True:
                # Check if client disconnected
                if await request.is_disconnected():
                    break
                
                # Get messages for this session
                if session_id in active_chats:
                    messages = active_chats[session_id]
                    
                    for msg in messages:
                        msg_id = msg['id']
                        msg_version = msg.get('version', 1)
                        
                        # Check if we need to send this message
                        if msg_id not in client_sent_messages or client_sent_messages[msg_id] < msg_version:
                            # Send message
                            yield f"data: {json.dumps(msg)}\n\n"
                            client_sent_messages[msg_id] = msg_version
                
                # Small delay to prevent busy waiting
                await asyncio.sleep(0.5)
                
        except asyncio.CancelledError:
            logger.info(f"Client {client_id} disconnected from session {session_id}")
            raise
        finally:
            logger.info(f"Cleaning up client {client_id}")
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # Disable Nginx buffering
        }
    )

async def process_ai_response(session_id: str, user_message: str, db: Session):
    """
    Process user message through n8n webhook
    """
    try:
        response_id = str(uuid.uuid4())
        
        # Initialize message versions if needed
        if session_id not in message_versions:
            message_versions[session_id] = {}
        
        # Add "thinking" status
        thinking_msg = {
            "id": response_id,
            "role": "assistant",
            "content": "...",
            "status": "thinking",
            "timestamp": datetime.now().isoformat(),
            "version": 1
        }
        active_chats[session_id].append(thinking_msg)
        message_versions[session_id][response_id] = 1
        
        # Call n8n webhook
        n8n_url = "http://n8n:5678/webhook/invoke_n8n_agent"
        
        try:
            # Prepare payload for n8n
            payload = {
                "sessionId": session_id,
                "chatInput": user_message
            }
            
            # Make request to n8n
            response = requests.post(
                n8n_url,
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                ai_response_text = result.get("output", "I couldn't process your request.")
                
                # Pass through n8n response directly for natural conversation
                ai_response = {"content": ai_response_text}
            else:
                logger.error(f"n8n webhook returned {response.status_code}: {response.text}")
                ai_response = {
                    "content": "I'm having trouble connecting to the AI service. Please try again later."
                }
                
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to connect to n8n: {e}")
            # Fallback to local response
            ai_response = await generate_ai_response(user_message, db)
        
        # IMPORTANT FIX: Remove the thinking message completely
        active_chats[session_id] = [
            msg for msg in active_chats[session_id] 
            if msg['id'] != response_id
        ]
        
        # Add complete message as NEW message
        complete_msg = {
            "id": response_id + "_complete",  # New unique ID
            "role": "assistant",
            "content": ai_response['content'],
            "status": "complete",
            "timestamp": datetime.now().isoformat(),
            "version": 1
        }
        if 'actions' in ai_response:
            complete_msg['actions'] = ai_response['actions']
        
        active_chats[session_id].append(complete_msg)
        
    except Exception as e:
        logger.error(f"AI processing error: {e}")
        error_msg = {
            "id": str(uuid.uuid4()),
            "role": "assistant",
            "content": f"Sorry, I encountered an error: {str(e)}",
            "status": "error",
            "timestamp": datetime.now().isoformat(),
            "version": 1
        }
        active_chats[session_id].append(error_msg)
        if session_id in message_versions:
            message_versions[session_id][error_msg['id']] = 1

async def parse_ai_response(response_text: str, db: Session) -> dict:
    """
    Parse AI response and extract book actions
    """
    response_lower = response_text.lower()
    
    # Check for book search results
    if "found" in response_lower and "book" in response_lower:
        # Extract book titles (simple pattern matching)
        # This would be enhanced based on n8n response format
        return {"content": response_text}
    
    # Check for save book commands
    if "save" in response_lower and any(word in response_lower for word in ["book", "added", "list"]):
        # Extract book ID if mentioned
        import re
        book_id_match = re.search(r'book\s*#?(\d+)', response_lower)
        if book_id_match:
            book_id = int(book_id_match.group(1))
            return {
                "content": response_text,
                "actions": {
                    "type": "save_book",
                    "book_id": book_id
                }
            }
    
    return {"content": response_text}

async def generate_ai_response(message: str, db: Session) -> dict:
    """
    Generate AI response based on message content - More natural responses
    """
    message_lower = message.lower()
    
    # Greetings
    if any(word in message_lower for word in ['hi', 'hello', 'hey', 'good morning', 'good afternoon']):
        greetings = [
            "Hello! How can I help you find your next great read today?",
            "Hi there! Looking for book recommendations or have something specific in mind?",
            "Hey! Ready to discover some amazing books?",
            "Hello! I'm here to help you explore our book collection. What interests you?"
        ]
        return {"content": random.choice(greetings)}
    
    # How are you
    elif any(phrase in message_lower for phrase in ['how are you', 'how do you do', "how's it going"]):
        responses = [
            "I'm doing great, thanks for asking! Always excited to talk about books. What kind of stories do you enjoy?",
            "I'm wonderful! Just here browsing through our amazing book collection. Are you looking for anything specific?",
            "Doing well, thank you! Ready to help you find your next favorite book!"
        ]
        return {"content": random.choice(responses)}
    
    # Casual conversation
    elif any(word in message_lower for word in ['joke', 'funny', 'laugh']):
        return {"content": "Why don't scientists trust atoms? Because they make up everything! üòÑ\n\nBut seriously, would you like me to find you some humor books?"}
    
    # Open questions about reading
    elif any(phrase in message_lower for phrase in ['think about reading', 'like reading', 'enjoy reading']):
        return {"content": "I think reading is one of life's greatest pleasures! It's amazing how books can transport us to different worlds, teach us new things, and help us see life from different perspectives. What genres do you usually enjoy?"}
    
    # Search for books
    elif any(word in message_lower for word in ['search', 'find', 'looking for', 'book about']):
        # Extract search query (simple approach)
        search_terms = message.replace('search', '').replace('find', '').replace('looking for', '').replace('book about', '').strip()
        
        books = BookService.search_books(db, search_terms)[:3]
        
        if books:
            response = f"I found {len(books)} books matching your search:\n\n"
            book_data = []
            for book in books:
                response += f"üìö **{book.title}** by {book.author}\n"
                if book.rating:
                    response += f"   ‚≠ê Rating: {book.rating}/5\n"
                book_data.append({
                    "id": book.id,
                    "title": book.title,
                    "author": book.author
                })
            
            return {
                "content": response,
                "actions": {
                    "type": "book_results",
                    "books": book_data
                }
            }
        else:
            return {"content": "I couldn't find any books matching your search. Try different keywords!"}
    
    # Get recommendations
    elif any(word in message_lower for word in ['recommend', 'suggestion', 'what should i read']):
        books = BookService.get_featured_books(db, limit=3)
        
        response = "Here are some books I recommend:\n\n"
        for book in books:
            response += f"üìñ **{book.title}** by {book.author}\n"
            if book.genres:
                response += f"   Genre: {', '.join([g.name for g in book.genres])}\n"
        
        return {"content": response}
    
    # Save book
    elif 'save' in message_lower and any(char.isdigit() for char in message):
        # Extract book ID (simple approach)
        book_id = ''.join(filter(str.isdigit, message))
        if book_id:
            return {
                "content": f"I'll save book #{book_id} to your list!",
                "actions": {
                    "type": "save_book",
                    "book_id": int(book_id)
                }
            }
    
    # Default - more natural
    else:
        defaults = [
            "I'm here to help you discover great books! Feel free to ask me anything about our collection.",
            "What kind of books are you in the mood for today?",
            "I'd love to help you find something to read. Any particular genre or topic interests you?",
            "Let me know what you're looking for - whether it's a specific book, genre, or just browsing!"
        ]
        return {"content": random.choice(defaults)}

@router.get("/history/{session_id}")
async def get_chat_history(
    session_id: str,
    limit: int = Query(50, ge=1, le=100)
):
    """
    Get chat history for a session
    """
    if session_id not in active_chats:
        return {"messages": []}
    
    messages = active_chats[session_id]
    # Remove version info before sending
    clean_messages = []
    for msg in messages[-limit:]:
        clean_msg = msg.copy()
        clean_msg.pop('version', None)
        clean_messages.append(clean_msg)
    
    return {
        "session_id": session_id,
        "messages": clean_messages,
        "total": len(messages)
    }

@router.delete("/clear/{session_id}")
async def clear_chat(session_id: str):
    """
    Clear chat history for a session
    """
    if session_id in active_chats:
        active_chats[session_id] = []
    if session_id in message_versions:
        message_versions[session_id] = {}
    
    return {"success": True, "message": "Chat history cleared"}
